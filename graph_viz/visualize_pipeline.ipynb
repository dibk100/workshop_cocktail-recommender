{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef37100c",
   "metadata": {},
   "source": [
    "# Visualize your graph   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "180e6111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dibaeck/miniconda3/envs/cikm_311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: Qwen/Qwen2.5-VL-3B-Instruct ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.35it/s]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 29959.31it/s]\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 29746.84it/s]\n",
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 31068.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded ✅\n",
      "Loading model: Qwen/Qwen2.5-VL-3B-Instruct ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.47it/s]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 23301.69it/s]\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 34100.03it/s]\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 18808.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded ✅\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from core.schemas import PipelineState\n",
    "from nodes.llm_task import llm_task_node\n",
    "from nodes.graph_nodes import graph_query_node\n",
    "from nodes.llm_response import llm_response_node\n",
    "from nodes.response_node import response_node\n",
    "from pipeline import build_pipeline_graph\n",
    "from core.schemas import PipelineState\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "app = build_pipeline_graph().compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae1507a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```mermaid\n",
       "---\n",
       "config:\n",
       "  flowchart:\n",
       "    curve: linear\n",
       "---\n",
       "graph TD;\n",
       "\t__start__([<p>__start__</p>]):::first\n",
       "\tLLM1(LLM1)\n",
       "\tGraphQuery(GraphQuery)\n",
       "\tLLM2(LLM2)\n",
       "\tResponseFormatter(ResponseFormatter)\n",
       "\t__end__([<p>__end__</p>]):::last\n",
       "\tGraphQuery --> LLM2;\n",
       "\tLLM1 --> GraphQuery;\n",
       "\tLLM2 --> ResponseFormatter;\n",
       "\t__start__ --> LLM1;\n",
       "\tResponseFormatter --> __end__;\n",
       "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
       "\tclassDef first fill-opacity:0\n",
       "\tclassDef last fill:#bfb6fc\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mermaid_code = app.get_graph().draw_mermaid()\n",
    "display(Markdown(f\"```mermaid\\n{mermaid_code}\\n```\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cikm_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
